{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fernandovieira1/ML-e-DS-com-Python-de-A-a-Z/blob/master/parte1_classif_svm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1V_C1WzIekfQ"
      },
      "source": [
        "## census"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r3ZkVoytZgPl"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "Nv99T9nEAezj",
        "outputId": "29fd88d4-2e9a-4eba-98f5-22276fd2bcc9"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# for fn in uploaded.keys():\n",
        "#   print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "#       name=fn, length=len(uploaded[fn])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wjr5U-Io51fs",
        "outputId": "af85cd85-b794-46d8-a158-24024f233be7"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XT-pv2FF7Hrm"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('census.pkl', 'rb') as f:\n",
        "  x_census_treinamento, y_census_treinamento, x_census_teste, y_census_teste = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tdr_wzc_Z5xH",
        "outputId": "a5fb664c-e004-4e13-a1b6-d8ead28a9714"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((27676, 108), (27676,))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_census_treinamento.shape, y_census_treinamento.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eqfSEmvaG0h",
        "outputId": "ba172722-45e2-4e4c-b9e7-d827ab824bc9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4885, 108), (4885,))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_census_teste.shape, y_census_teste.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "54.5"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# decidar qtas. camadas ocultas: nr. entradas + 1 / 2\n",
        "(108+1)/2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3qoy_VMaOjy",
        "outputId": "cdc69a5a-d875-4006-e8ca-5dacc42e8cc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.40100079\n",
            "Iteration 2, loss = 0.32924917\n",
            "Iteration 3, loss = 0.31531252\n",
            "Iteration 4, loss = 0.30808675\n",
            "Iteration 5, loss = 0.30243601\n",
            "Iteration 6, loss = 0.29909116\n",
            "Iteration 7, loss = 0.29594624\n",
            "Iteration 8, loss = 0.29274821\n",
            "Iteration 9, loss = 0.28952497\n",
            "Iteration 10, loss = 0.28790246\n",
            "Iteration 11, loss = 0.28628435\n",
            "Iteration 12, loss = 0.28338776\n",
            "Iteration 13, loss = 0.28131155\n",
            "Iteration 14, loss = 0.28016021\n",
            "Iteration 15, loss = 0.27708300\n",
            "Iteration 16, loss = 0.27598497\n",
            "Iteration 17, loss = 0.27452957\n",
            "Iteration 18, loss = 0.27257655\n",
            "Iteration 19, loss = 0.27109190\n",
            "Iteration 20, loss = 0.27001225\n",
            "Iteration 21, loss = 0.26869313\n",
            "Iteration 22, loss = 0.26611485\n",
            "Iteration 23, loss = 0.26486368\n",
            "Iteration 24, loss = 0.26320271\n",
            "Iteration 25, loss = 0.26132325\n",
            "Iteration 26, loss = 0.26055468\n",
            "Iteration 27, loss = 0.25896293\n",
            "Iteration 28, loss = 0.25717340\n",
            "Iteration 29, loss = 0.25630592\n",
            "Iteration 30, loss = 0.25498511\n",
            "Iteration 31, loss = 0.25369824\n",
            "Iteration 32, loss = 0.25301715\n",
            "Iteration 33, loss = 0.25255982\n",
            "Iteration 34, loss = 0.25048658\n",
            "Iteration 35, loss = 0.24901924\n",
            "Iteration 36, loss = 0.24753212\n",
            "Iteration 37, loss = 0.24603335\n",
            "Iteration 38, loss = 0.24608708\n",
            "Iteration 39, loss = 0.24394151\n",
            "Iteration 40, loss = 0.24267223\n",
            "Iteration 41, loss = 0.24217414\n",
            "Iteration 42, loss = 0.24043800\n",
            "Iteration 43, loss = 0.23915235\n",
            "Iteration 44, loss = 0.23953512\n",
            "Iteration 45, loss = 0.23818004\n",
            "Iteration 46, loss = 0.23742388\n",
            "Iteration 47, loss = 0.23562274\n",
            "Iteration 48, loss = 0.23415105\n",
            "Iteration 49, loss = 0.23394328\n",
            "Iteration 50, loss = 0.23257360\n",
            "Iteration 51, loss = 0.23246929\n",
            "Iteration 52, loss = 0.23105072\n",
            "Iteration 53, loss = 0.22925907\n",
            "Iteration 54, loss = 0.22812011\n",
            "Iteration 55, loss = 0.22715081\n",
            "Iteration 56, loss = 0.22663249\n",
            "Iteration 57, loss = 0.22621469\n",
            "Iteration 58, loss = 0.22534135\n",
            "Iteration 59, loss = 0.22394619\n",
            "Iteration 60, loss = 0.22285589\n",
            "Iteration 61, loss = 0.22279099\n",
            "Iteration 62, loss = 0.22241528\n",
            "Iteration 63, loss = 0.22199387\n",
            "Iteration 64, loss = 0.22167273\n",
            "Iteration 65, loss = 0.21923789\n",
            "Iteration 66, loss = 0.21916743\n",
            "Iteration 67, loss = 0.21862737\n",
            "Iteration 68, loss = 0.21742164\n",
            "Iteration 69, loss = 0.21638220\n",
            "Iteration 70, loss = 0.21572891\n",
            "Iteration 71, loss = 0.21533073\n",
            "Iteration 72, loss = 0.21349146\n",
            "Iteration 73, loss = 0.21333938\n",
            "Iteration 74, loss = 0.21200426\n",
            "Iteration 75, loss = 0.21180736\n",
            "Iteration 76, loss = 0.21130217\n",
            "Iteration 77, loss = 0.21113747\n",
            "Iteration 78, loss = 0.21170711\n",
            "Iteration 79, loss = 0.20985153\n",
            "Iteration 80, loss = 0.20887481\n",
            "Iteration 81, loss = 0.20939148\n",
            "Iteration 82, loss = 0.20765943\n",
            "Iteration 83, loss = 0.20697670\n",
            "Iteration 84, loss = 0.20551744\n",
            "Iteration 85, loss = 0.20671091\n",
            "Iteration 86, loss = 0.20582696\n",
            "Iteration 87, loss = 0.20453461\n",
            "Iteration 88, loss = 0.20387610\n",
            "Iteration 89, loss = 0.20575726\n",
            "Iteration 90, loss = 0.20375281\n",
            "Iteration 91, loss = 0.20240966\n",
            "Iteration 92, loss = 0.20282280\n",
            "Iteration 93, loss = 0.20066124\n",
            "Iteration 94, loss = 0.20049708\n",
            "Iteration 95, loss = 0.20083175\n",
            "Iteration 96, loss = 0.19997658\n",
            "Iteration 97, loss = 0.20076786\n",
            "Iteration 98, loss = 0.19878267\n",
            "Iteration 99, loss = 0.19827042\n",
            "Iteration 100, loss = 0.19727439\n",
            "Iteration 101, loss = 0.19830514\n",
            "Iteration 102, loss = 0.19679454\n",
            "Iteration 103, loss = 0.19546859\n",
            "Iteration 104, loss = 0.19677611\n",
            "Iteration 105, loss = 0.19574920\n",
            "Iteration 106, loss = 0.19493456\n",
            "Iteration 107, loss = 0.19560220\n",
            "Iteration 108, loss = 0.19477700\n",
            "Iteration 109, loss = 0.19359709\n",
            "Iteration 110, loss = 0.19290077\n",
            "Iteration 111, loss = 0.19242670\n",
            "Iteration 112, loss = 0.19385668\n",
            "Iteration 113, loss = 0.19301665\n",
            "Iteration 114, loss = 0.19171493\n",
            "Iteration 115, loss = 0.19109627\n",
            "Iteration 116, loss = 0.19065524\n",
            "Iteration 117, loss = 0.19041693\n",
            "Iteration 118, loss = 0.18957258\n",
            "Iteration 119, loss = 0.18997303\n",
            "Iteration 120, loss = 0.18899027\n",
            "Iteration 121, loss = 0.18954316\n",
            "Iteration 122, loss = 0.19086453\n",
            "Iteration 123, loss = 0.18840957\n",
            "Iteration 124, loss = 0.18746339\n",
            "Iteration 125, loss = 0.18774355\n",
            "Iteration 126, loss = 0.18662128\n",
            "Iteration 127, loss = 0.18676571\n",
            "Iteration 128, loss = 0.18638989\n",
            "Iteration 129, loss = 0.18586702\n",
            "Iteration 130, loss = 0.18568532\n",
            "Iteration 131, loss = 0.18583693\n",
            "Iteration 132, loss = 0.18457105\n",
            "Iteration 133, loss = 0.18496279\n",
            "Iteration 134, loss = 0.18406565\n",
            "Iteration 135, loss = 0.18330850\n",
            "Iteration 136, loss = 0.18384906\n",
            "Iteration 137, loss = 0.18225799\n",
            "Iteration 138, loss = 0.18284142\n",
            "Iteration 139, loss = 0.18280969\n",
            "Iteration 140, loss = 0.18182070\n",
            "Iteration 141, loss = 0.18261643\n",
            "Iteration 142, loss = 0.18143743\n",
            "Iteration 143, loss = 0.18066155\n",
            "Iteration 144, loss = 0.18024204\n",
            "Iteration 145, loss = 0.18022717\n",
            "Iteration 146, loss = 0.18100259\n",
            "Iteration 147, loss = 0.17981508\n",
            "Iteration 148, loss = 0.17976764\n",
            "Iteration 149, loss = 0.17807413\n",
            "Iteration 150, loss = 0.18086018\n",
            "Iteration 151, loss = 0.17747672\n",
            "Iteration 152, loss = 0.17823398\n",
            "Iteration 153, loss = 0.17653422\n",
            "Iteration 154, loss = 0.17763913\n",
            "Iteration 155, loss = 0.17640296\n",
            "Iteration 156, loss = 0.17643375\n",
            "Iteration 157, loss = 0.17594900\n",
            "Iteration 158, loss = 0.17697752\n",
            "Iteration 159, loss = 0.17702732\n",
            "Iteration 160, loss = 0.17595372\n",
            "Iteration 161, loss = 0.17431339\n",
            "Iteration 162, loss = 0.17519844\n",
            "Iteration 163, loss = 0.17430433\n",
            "Iteration 164, loss = 0.17609447\n",
            "Iteration 165, loss = 0.17411559\n",
            "Iteration 166, loss = 0.17442054\n",
            "Iteration 167, loss = 0.17379712\n",
            "Iteration 168, loss = 0.17167534\n",
            "Iteration 169, loss = 0.17253478\n",
            "Iteration 170, loss = 0.17353584\n",
            "Iteration 171, loss = 0.17305258\n",
            "Iteration 172, loss = 0.17292877\n",
            "Iteration 173, loss = 0.17367519\n",
            "Iteration 174, loss = 0.17295976\n",
            "Iteration 175, loss = 0.17127588\n",
            "Iteration 176, loss = 0.17234664\n",
            "Iteration 177, loss = 0.17150356\n",
            "Iteration 178, loss = 0.16922575\n",
            "Iteration 179, loss = 0.17028888\n",
            "Iteration 180, loss = 0.16978212\n",
            "Iteration 181, loss = 0.17050030\n",
            "Iteration 182, loss = 0.16937833\n",
            "Iteration 183, loss = 0.16842417\n",
            "Iteration 184, loss = 0.17009097\n",
            "Iteration 185, loss = 0.17073355\n",
            "Iteration 186, loss = 0.16748527\n",
            "Iteration 187, loss = 0.16879337\n",
            "Iteration 188, loss = 0.16804720\n",
            "Iteration 189, loss = 0.16775886\n",
            "Iteration 190, loss = 0.16707182\n",
            "Iteration 191, loss = 0.16711142\n",
            "Iteration 192, loss = 0.16767730\n",
            "Iteration 193, loss = 0.16607362\n",
            "Iteration 194, loss = 0.16607836\n",
            "Iteration 195, loss = 0.16610614\n",
            "Iteration 196, loss = 0.16696030\n",
            "Iteration 197, loss = 0.16578260\n",
            "Iteration 198, loss = 0.16631360\n",
            "Iteration 199, loss = 0.16496193\n",
            "Iteration 200, loss = 0.16511898\n",
            "Iteration 201, loss = 0.16490045\n",
            "Iteration 202, loss = 0.16486911\n",
            "Iteration 203, loss = 0.16329298\n",
            "Iteration 204, loss = 0.16463218\n",
            "Iteration 205, loss = 0.16295852\n",
            "Iteration 206, loss = 0.16149836\n",
            "Iteration 207, loss = 0.16211783\n",
            "Iteration 208, loss = 0.16298122\n",
            "Iteration 209, loss = 0.16279628\n",
            "Iteration 210, loss = 0.16342088\n",
            "Iteration 211, loss = 0.16254200\n",
            "Iteration 212, loss = 0.16264237\n",
            "Iteration 213, loss = 0.16298649\n",
            "Iteration 214, loss = 0.16167525\n",
            "Iteration 215, loss = 0.16243336\n",
            "Iteration 216, loss = 0.15961803\n",
            "Iteration 217, loss = 0.16073847\n",
            "Iteration 218, loss = 0.16009584\n",
            "Iteration 219, loss = 0.15912714\n",
            "Iteration 220, loss = 0.16025382\n",
            "Iteration 221, loss = 0.15934746\n",
            "Iteration 222, loss = 0.15990598\n",
            "Iteration 223, loss = 0.15871152\n",
            "Iteration 224, loss = 0.16139806\n",
            "Iteration 225, loss = 0.15779346\n",
            "Iteration 226, loss = 0.15961359\n",
            "Iteration 227, loss = 0.15914912\n",
            "Iteration 228, loss = 0.15660525\n",
            "Iteration 229, loss = 0.15809358\n",
            "Iteration 230, loss = 0.15894918\n",
            "Iteration 231, loss = 0.15818927\n",
            "Iteration 232, loss = 0.15722204\n",
            "Iteration 233, loss = 0.15774253\n",
            "Iteration 234, loss = 0.15750077\n",
            "Iteration 235, loss = 0.15661939\n",
            "Iteration 236, loss = 0.15488332\n",
            "Iteration 237, loss = 0.15796950\n",
            "Iteration 238, loss = 0.15660684\n",
            "Iteration 239, loss = 0.15655348\n",
            "Iteration 240, loss = 0.15501299\n",
            "Iteration 241, loss = 0.15464478\n",
            "Iteration 242, loss = 0.15633306\n",
            "Iteration 243, loss = 0.15609442\n",
            "Iteration 244, loss = 0.15500000\n",
            "Iteration 245, loss = 0.15433037\n",
            "Iteration 246, loss = 0.15415853\n",
            "Iteration 247, loss = 0.15381817\n",
            "Iteration 248, loss = 0.15576359\n",
            "Iteration 249, loss = 0.15434527\n",
            "Iteration 250, loss = 0.15586137\n",
            "Iteration 251, loss = 0.15319427\n",
            "Iteration 252, loss = 0.15395490\n",
            "Iteration 253, loss = 0.15194640\n",
            "Iteration 254, loss = 0.15160658\n",
            "Iteration 255, loss = 0.15413736\n",
            "Iteration 256, loss = 0.15167504\n",
            "Iteration 257, loss = 0.15288210\n",
            "Iteration 258, loss = 0.15188785\n",
            "Iteration 259, loss = 0.15086903\n",
            "Iteration 260, loss = 0.15213067\n",
            "Iteration 261, loss = 0.15138568\n",
            "Iteration 262, loss = 0.15195927\n",
            "Iteration 263, loss = 0.15214086\n",
            "Iteration 264, loss = 0.15157225\n",
            "Iteration 265, loss = 0.15222665\n",
            "Iteration 266, loss = 0.15193545\n",
            "Iteration 267, loss = 0.15037284\n",
            "Iteration 268, loss = 0.15016976\n",
            "Iteration 269, loss = 0.15070992\n",
            "Iteration 270, loss = 0.14955760\n",
            "Iteration 271, loss = 0.14981551\n",
            "Iteration 272, loss = 0.14999864\n",
            "Iteration 273, loss = 0.14919667\n",
            "Iteration 274, loss = 0.15017913\n",
            "Iteration 275, loss = 0.14962117\n",
            "Iteration 276, loss = 0.14859915\n",
            "Iteration 277, loss = 0.14838070\n",
            "Iteration 278, loss = 0.14817936\n",
            "Iteration 279, loss = 0.14932313\n",
            "Iteration 280, loss = 0.14954134\n",
            "Iteration 281, loss = 0.14723564\n",
            "Iteration 282, loss = 0.14807012\n",
            "Iteration 283, loss = 0.15079511\n",
            "Iteration 284, loss = 0.14693123\n",
            "Iteration 285, loss = 0.14699515\n",
            "Iteration 286, loss = 0.14758674\n",
            "Iteration 287, loss = 0.14879216\n",
            "Iteration 288, loss = 0.14657424\n",
            "Iteration 289, loss = 0.14728292\n",
            "Iteration 290, loss = 0.14610504\n",
            "Iteration 291, loss = 0.14544758\n",
            "Iteration 292, loss = 0.14817291\n",
            "Iteration 293, loss = 0.14837747\n",
            "Iteration 294, loss = 0.14683375\n",
            "Iteration 295, loss = 0.14621357\n",
            "Iteration 296, loss = 0.14507351\n",
            "Iteration 297, loss = 0.14510390\n",
            "Iteration 298, loss = 0.14625305\n",
            "Iteration 299, loss = 0.14510752\n",
            "Iteration 300, loss = 0.14409087\n",
            "Iteration 301, loss = 0.14594502\n",
            "Iteration 302, loss = 0.14454760\n",
            "Iteration 303, loss = 0.14506760\n",
            "Iteration 304, loss = 0.14456651\n",
            "Iteration 305, loss = 0.14639889\n",
            "Iteration 306, loss = 0.14563051\n",
            "Iteration 307, loss = 0.14465319\n",
            "Iteration 308, loss = 0.14347492\n",
            "Iteration 309, loss = 0.14315453\n",
            "Iteration 310, loss = 0.14456533\n",
            "Iteration 311, loss = 0.14293808\n",
            "Iteration 312, loss = 0.14388884\n",
            "Iteration 313, loss = 0.14450282\n",
            "Iteration 314, loss = 0.14534315\n",
            "Iteration 315, loss = 0.14649909\n",
            "Iteration 316, loss = 0.14256654\n",
            "Iteration 317, loss = 0.14328936\n",
            "Iteration 318, loss = 0.14188690\n",
            "Iteration 319, loss = 0.14154183\n",
            "Iteration 320, loss = 0.14322253\n",
            "Iteration 321, loss = 0.14127549\n",
            "Iteration 322, loss = 0.14020723\n",
            "Iteration 323, loss = 0.14150173\n",
            "Iteration 324, loss = 0.14426717\n",
            "Iteration 325, loss = 0.14094744\n",
            "Iteration 326, loss = 0.14331588\n",
            "Iteration 327, loss = 0.14328333\n",
            "Iteration 328, loss = 0.14211501\n",
            "Iteration 329, loss = 0.14240746\n",
            "Iteration 330, loss = 0.14202667\n",
            "Iteration 331, loss = 0.14094758\n",
            "Iteration 332, loss = 0.14173019\n",
            "Iteration 333, loss = 0.14175057\n",
            "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=(55, 55), max_iter=1000, tol=1e-05,\n",
              "              verbose=True)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rede_neural_census = MLPClassifier(max_iter=1000, verbose=True, tol=0.00001, solver='adam', activation='relu', hidden_layer_sizes=(55,55)) \n",
        "# verbose: mostra os erros (loss), o que ajuda a comparar se o gradiente descendente esta funcionando conforme as iteracoes nos pesos acontecem.\n",
        "# tol: de epoca em epoca o valor do erro tem de diminuir conforme o tempo passa (qto mais, maior o numero de iteracoes)\n",
        "# Estas duas variaveis sao criticas -- \"brincar\" com elas\n",
        "# Consultar a documentacao e pesquisar se vale a pena alterar outros valores padrao/default\n",
        "\n",
        "rede_neural_census.fit(x_census_treinamento, y_census_treinamento)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7_xyTQta_KV",
        "outputId": "3e360910-3cba-4249-828c-66876261a7e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([' <=50K', ' <=50K', ' <=50K', ..., ' <=50K', ' <=50K', ' >50K'],\n",
              "      dtype='<U6')"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "previsoes = rede_neural_census.predict(x_census_teste)\n",
        "previsoes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz7w4OqHbO55",
        "outputId": "0b98516e-1db8-4d62-c0c5-c21eb6ec4256"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([' <=50K', ' <=50K', ' <=50K', ..., ' <=50K', ' <=50K', ' <=50K'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_census_teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3y9zwsUpbUBb",
        "outputId": "f8047674-c5eb-43e2-8a7c-2bbfc4098bf0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8176049129989764"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "accuracy_score(y_census_teste, previsoes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKP4c7sUbjrr",
        "outputId": "7d6273b4-f245-4f1b-ddb7-9f8b1cd7474f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.88      0.88      0.88      3693\n",
            "        >50K       0.63      0.62      0.62      1192\n",
            "\n",
            "    accuracy                           0.82      4885\n",
            "   macro avg       0.75      0.75      0.75      4885\n",
            "weighted avg       0.82      0.82      0.82      4885\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_census_teste, previsoes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "ljPW7ajodUIY",
        "outputId": "e0ddc12c-d591-4037-f51f-400be46ad8fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8176049129989764"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from yellowbrick.classifier import ConfusionMatrix\n",
        "cm = ConfusionMatrix(rede_neural_census)\n",
        "cm.fit(x_census_treinamento, y_census_treinamento)\n",
        "cm.score(x_census_teste, y_census_teste)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPV9CYGxDG9QXnbgJm0Gtn+",
      "include_colab_link": true,
      "name": "parte1_classif_knn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
